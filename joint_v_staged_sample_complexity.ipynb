{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WvmtEh42mViU"
   },
   "source": [
    "# Imports and utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "eJx9ma02mX5Z"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import argparse\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data.dataset import random_split\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "yXTauo6LmYX8"
   },
   "outputs": [],
   "source": [
    "from neural_network import *\n",
    "from utils import *\n",
    "from metrics import *\n",
    "from training_helpers import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RePVfWZwmfgd",
    "outputId": "b5afc646-32dc-4baa-d443-1071d5dcca58"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "lLSngoolmi2d"
   },
   "outputs": [],
   "source": [
    "k = 5 # number of classes expert can predict\n",
    "n_dataset = 10\n",
    "Expert = synth_expert(k, n_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "referenced_widgets": [
      "388a5b0fe7b84ba88a618affdc70d5b4",
      "343a6794baea4d56b8d943ffc5c8a3e5",
      "2d83b4dbdb93474b94d67299c9d0c403",
      "8676435c0184460ebf790190a7acce63",
      "08a984939466469787ceeaed669b837a",
      "13afdf908e9d429ebf46f0805ccc84c8",
      "6e49c91cb70049e68eeb1396ead9d39e",
      "92dbd1bb64514b3c8b510408a5fd59db",
      "6efc410ba6a74ba0a1c1b29fc2d32957",
      "b5a8afad6ae54f63ad4a491e1b1f7878",
      "b9a72ba4fd4c4e51b2e18240c4144066"
     ]
    },
    "id": "SBJvS3QpmkQl",
    "outputId": "a2961984-8669-4385-c29e-96e315b50c2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "use_data_aug = False\n",
    "n_dataset = 10  # cifar-10\n",
    "normalize = transforms.Normalize(mean=[x / 255.0 for x in [125.3, 123.0, 113.9]],\n",
    "                                    std=[x / 255.0 for x in [63.0, 62.1, 66.7]])\n",
    "\n",
    "if use_data_aug:\n",
    "    transform_train = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Lambda(lambda x: F.pad(x.unsqueeze(0),\n",
    "                                            (4, 4, 4, 4), mode='reflect').squeeze()),\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.RandomCrop(32),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ])\n",
    "else:\n",
    "    transform_train = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ])\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])\n",
    "\n",
    "if n_dataset == 10:\n",
    "    dataset = 'cifar10'\n",
    "elif n_dataset == 100:\n",
    "    dataset = 'cifar100'\n",
    "\n",
    "kwargs = {'num_workers': 0, 'pin_memory': True}\n",
    "\n",
    "\n",
    "train_dataset_all = datasets.__dict__[dataset.upper()]('../data', train=True, download=True,\n",
    "                                                        transform=transform_train)\n",
    "train_size = int(0.90 * len(train_dataset_all))\n",
    "test_size = len(train_dataset_all) - train_size\n",
    "\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(train_dataset_all, [train_size, test_size])\n",
    "#train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "#                                           batch_size=128, shuffle=True, **kwargs)\n",
    "#val_loader = torch.utils.data.DataLoader(val_dataset,\n",
    "#                                            batch_size=128, shuffle=True, **kwargs)\n",
    "\n",
    "\n",
    "normalize = transforms.Normalize(mean=[x / 255.0 for x in [125.3, 123.0, 113.9]],\n",
    "                                 std=[x / 255.0 for x in [63.0, 62.1, 66.7]])\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True}\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])\n",
    "test_dataset = datasets.__dict__[\"cifar10\".upper()]('../data', train=False, transform=transform_test, download=True)\n",
    "#test_loader = torch.utils.data.DataLoader(\n",
    "#    datasets.__dict__[\"cifar100\".upper()]('../data', train=False, transform=transform_test, download=True),\n",
    "#    batch_size=128, shuffle=True, **kwargs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "0YmBYZg1mlo_"
   },
   "outputs": [],
   "source": [
    "class CifarExpertDataset(Dataset):\n",
    "    def __init__(self, images, targets, expert_fn, labeled, indices = None):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        self.images = images\n",
    "        self.targets = np.array(targets)\n",
    "        self.expert_fn = expert_fn\n",
    "        self.labeled = np.array(labeled)\n",
    "        self.expert_preds = np.array(expert_fn(None, torch.FloatTensor(targets)))\n",
    "        for i in range(len(self.expert_preds)):\n",
    "            if self.labeled[i] == 0:\n",
    "                self.expert_preds[i] = -1 # not labeled by expert\n",
    "        if indices != None:\n",
    "            self.indices = indices\n",
    "        else:\n",
    "            self.indices = np.array(list(range(len(self.targets))))\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Take the index of item and returns the image, label, expert prediction and index in original dataset\"\"\"\n",
    "        label = self.targets[index]\n",
    "        image = transform_test(self.images[index])\n",
    "        expert_pred = self.expert_preds[index]\n",
    "        indice = self.indices[index]\n",
    "        labeled = self.labeled[index]\n",
    "        return torch.FloatTensor(image), label, expert_pred, indice, labeled\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "rI_kDhh5mm2b"
   },
   "outputs": [],
   "source": [
    "dataset_train = CifarExpertDataset(np.array(train_dataset.dataset.data)[train_dataset.indices], np.array(train_dataset.dataset.targets)[train_dataset.indices], Expert.predict , [1]*len(train_dataset.indices))\n",
    "dataset_val = CifarExpertDataset(np.array(val_dataset.dataset.data)[val_dataset.indices], np.array(val_dataset.dataset.targets)[val_dataset.indices], Expert.predict , [1]*len(val_dataset.indices))\n",
    "dataset_test = CifarExpertDataset(test_dataset.data , test_dataset.targets, Expert.predict , [1]*len(test_dataset.targets))\n",
    "\n",
    "dataLoaderTrain = DataLoader(dataset=dataset_train, batch_size=128, shuffle=True,  num_workers=0, pin_memory=True)\n",
    "dataLoaderVal = DataLoader(dataset=dataset_val, batch_size=128, shuffle=False,  num_workers=0, pin_memory=True)\n",
    "dataLoaderTest = DataLoader(dataset=dataset_test, batch_size=128, shuffle=False,  num_workers=0, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t5utTPLKmnNX"
   },
   "source": [
    "# Figure 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "-gUQYd73Hggl"
   },
   "outputs": [],
   "source": [
    "all_indices = list(range(len(train_dataset.indices)))\n",
    "all_data_x = np.array(train_dataset.dataset.data)[train_dataset.indices]\n",
    "all_data_y = np.array(train_dataset.dataset.targets)[train_dataset.indices]\n",
    "\n",
    "intial_random_set = random.sample(all_indices, 20)\n",
    "indices_labeled  = intial_random_set\n",
    "indices_unlabeled= list(set(all_indices) - set(indices_labeled))\n",
    "\n",
    "dataset_train_labeled = CifarExpertDataset(all_data_x[indices_labeled], all_data_y[indices_labeled], Expert.predict , [1]*len(indices_labeled), indices_labeled)\n",
    "dataset_train_unlabeled = CifarExpertDataset(all_data_x[indices_unlabeled], all_data_y[indices_unlabeled], Expert.predict , [0]*len(indices_unlabeled), indices_unlabeled)\n",
    "\n",
    "dataLoaderTrainLabeled = DataLoader(dataset=dataset_train_labeled, batch_size=128, shuffle=True,  num_workers=0, pin_memory=True)\n",
    "dataLoaderTrainUnlabeled = DataLoader(dataset=dataset_train_unlabeled, batch_size=128, shuffle=True,  num_workers=0, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_TRIALS = 1\n",
    "EPOCHS = 30\n",
    "EPOCHS_ALPHA = 15\n",
    "data_sizes = [0.01, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.99]\n",
    "data_sizes = [0.01]\n",
    "alpha_grid = [0, 0.1,  0.5, 1]\n",
    "joint_results = []\n",
    "seperate_results = []\n",
    "joint_semisupervised_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "AG8OYFfRmoEH",
    "outputId": "0a7f9fd2-f350-4a0a-f652-f7ec56baee14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      " datas size 0.01 \n",
      " \n",
      "\n",
      " \n",
      " Joint \n",
      "\n",
      "\n",
      " Joint semi-supervised\n",
      "Number of model parameters: 6523911\n",
      "Epoch: [0][0/352]\tTime 0.304 (0.304)\tLoss 3.4656 (3.4656)\tPrec@1 7.812 (7.812)\n",
      "Epoch: [0][10/352]\tTime 0.281 (0.288)\tLoss 2.9817 (3.1982)\tPrec@1 21.094 (15.767)\n",
      "Epoch: [0][20/352]\tTime 0.303 (0.286)\tLoss 2.9030 (3.0507)\tPrec@1 24.219 (20.759)\n",
      "Epoch: [0][30/352]\tTime 0.279 (0.285)\tLoss 2.5370 (2.9426)\tPrec@1 32.031 (23.513)\n",
      "Epoch: [0][40/352]\tTime 0.276 (0.284)\tLoss 2.6783 (2.8405)\tPrec@1 31.250 (26.334)\n",
      "Epoch: [0][50/352]\tTime 0.294 (0.284)\tLoss 2.4699 (2.7697)\tPrec@1 34.375 (28.156)\n",
      "Epoch: [0][60/352]\tTime 0.339 (0.288)\tLoss 2.1966 (2.7075)\tPrec@1 44.531 (29.828)\n",
      "Epoch: [0][70/352]\tTime 0.278 (0.289)\tLoss 2.0934 (2.6469)\tPrec@1 43.750 (31.382)\n",
      "Epoch: [0][80/352]\tTime 0.317 (0.291)\tLoss 2.4564 (2.6066)\tPrec@1 38.281 (32.649)\n",
      "Epoch: [0][90/352]\tTime 0.315 (0.291)\tLoss 2.4288 (2.5653)\tPrec@1 36.719 (33.774)\n",
      "Epoch: [0][100/352]\tTime 0.283 (0.291)\tLoss 2.2850 (2.5481)\tPrec@1 40.625 (34.213)\n",
      "Epoch: [0][110/352]\tTime 0.306 (0.291)\tLoss 2.0561 (2.5178)\tPrec@1 49.219 (35.044)\n",
      "Epoch: [0][120/352]\tTime 0.280 (0.292)\tLoss 2.1172 (2.4869)\tPrec@1 43.750 (35.899)\n",
      "Epoch: [0][130/352]\tTime 0.286 (0.292)\tLoss 2.0131 (2.4562)\tPrec@1 50.781 (36.868)\n",
      "Epoch: [0][140/352]\tTime 0.296 (0.292)\tLoss 2.3332 (2.4317)\tPrec@1 47.656 (37.633)\n",
      "Epoch: [0][150/352]\tTime 0.290 (0.291)\tLoss 1.9486 (2.4019)\tPrec@1 46.875 (38.230)\n",
      "Epoch: [0][160/352]\tTime 0.281 (0.291)\tLoss 1.9728 (2.3759)\tPrec@1 49.219 (38.941)\n",
      "Epoch: [0][170/352]\tTime 0.295 (0.291)\tLoss 1.8400 (2.3549)\tPrec@1 54.688 (39.497)\n",
      "Epoch: [0][180/352]\tTime 0.276 (0.291)\tLoss 1.9576 (2.3308)\tPrec@1 48.438 (40.211)\n",
      "Epoch: [0][190/352]\tTime 0.322 (0.291)\tLoss 1.8638 (2.3072)\tPrec@1 57.031 (40.785)\n",
      "Epoch: [0][200/352]\tTime 0.278 (0.291)\tLoss 1.9964 (2.2901)\tPrec@1 52.344 (41.259)\n",
      "Epoch: [0][210/352]\tTime 0.285 (0.290)\tLoss 1.6569 (2.2679)\tPrec@1 59.375 (41.880)\n",
      "Epoch: [0][220/352]\tTime 0.284 (0.290)\tLoss 1.8734 (2.2459)\tPrec@1 55.469 (42.442)\n",
      "Epoch: [0][230/352]\tTime 0.280 (0.289)\tLoss 2.0819 (2.2318)\tPrec@1 43.750 (42.790)\n",
      "Epoch: [0][240/352]\tTime 0.278 (0.289)\tLoss 1.8604 (2.2150)\tPrec@1 54.688 (43.293)\n",
      "Epoch: [0][250/352]\tTime 0.278 (0.289)\tLoss 1.7638 (2.1996)\tPrec@1 55.469 (43.725)\n",
      "Epoch: [0][260/352]\tTime 0.286 (0.288)\tLoss 1.5011 (2.1803)\tPrec@1 65.625 (44.307)\n",
      "Epoch: [0][270/352]\tTime 0.278 (0.288)\tLoss 1.9942 (2.1715)\tPrec@1 50.000 (44.681)\n",
      "Epoch: [0][280/352]\tTime 0.296 (0.288)\tLoss 1.4906 (2.1519)\tPrec@1 59.375 (45.193)\n",
      "Epoch: [0][290/352]\tTime 0.296 (0.288)\tLoss 1.7171 (2.1367)\tPrec@1 52.344 (45.616)\n",
      "Epoch: [0][300/352]\tTime 0.296 (0.289)\tLoss 1.8393 (2.1232)\tPrec@1 50.781 (45.935)\n",
      "Epoch: [0][310/352]\tTime 0.299 (0.289)\tLoss 1.8746 (2.1092)\tPrec@1 57.031 (46.363)\n",
      "Epoch: [0][320/352]\tTime 0.300 (0.290)\tLoss 1.5317 (2.0968)\tPrec@1 63.281 (46.712)\n",
      "Epoch: [0][330/352]\tTime 0.298 (0.290)\tLoss 1.6236 (2.0838)\tPrec@1 53.125 (47.012)\n",
      "Epoch: [0][340/352]\tTime 0.295 (0.290)\tLoss 1.7215 (2.0748)\tPrec@1 56.250 (47.255)\n",
      "Epoch: [0][350/352]\tTime 0.310 (0.290)\tLoss 1.6985 (2.0643)\tPrec@1 57.031 (47.529)\n",
      "Epoch: [1][0/352]\tTime 0.305 (0.305)\tLoss 1.6437 (1.6437)\tPrec@1 61.719 (61.719)\n",
      "Epoch: [1][10/352]\tTime 0.296 (0.299)\tLoss 1.5911 (1.5875)\tPrec@1 60.938 (60.724)\n",
      "Epoch: [1][20/352]\tTime 0.296 (0.298)\tLoss 1.5191 (1.5714)\tPrec@1 64.062 (61.942)\n",
      "Epoch: [1][30/352]\tTime 0.293 (0.297)\tLoss 1.6800 (1.5897)\tPrec@1 57.812 (61.341)\n",
      "Epoch: [1][40/352]\tTime 0.300 (0.297)\tLoss 1.6425 (1.5950)\tPrec@1 60.156 (61.014)\n",
      "Epoch: [1][50/352]\tTime 0.303 (0.298)\tLoss 1.5947 (1.5901)\tPrec@1 58.594 (61.075)\n",
      "Epoch: [1][60/352]\tTime 0.293 (0.299)\tLoss 1.2880 (1.5869)\tPrec@1 64.844 (60.809)\n",
      "Epoch: [1][70/352]\tTime 0.295 (0.300)\tLoss 1.3254 (1.5773)\tPrec@1 67.969 (61.081)\n",
      "Epoch: [1][80/352]\tTime 0.296 (0.299)\tLoss 1.5195 (1.5701)\tPrec@1 61.719 (61.372)\n",
      "Epoch: [1][90/352]\tTime 0.294 (0.299)\tLoss 1.3203 (1.5593)\tPrec@1 63.281 (61.684)\n",
      "Epoch: [1][100/352]\tTime 0.298 (0.299)\tLoss 1.3746 (1.5482)\tPrec@1 64.062 (62.129)\n",
      "Epoch: [1][110/352]\tTime 0.294 (0.299)\tLoss 1.4257 (1.5364)\tPrec@1 62.500 (62.366)\n",
      "Epoch: [1][120/352]\tTime 0.296 (0.299)\tLoss 1.5556 (1.5362)\tPrec@1 64.844 (62.358)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [11], line 69\u001b[0m\n\u001b[1;32m     67\u001b[0m net_r_params \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m [\u001b[38;5;241m100\u001b[39m,\u001b[38;5;241m100\u001b[39m,\u001b[38;5;241m1000\u001b[39m,\u001b[38;5;241m500\u001b[39m]\n\u001b[1;32m     68\u001b[0m model_2_r \u001b[38;5;241m=\u001b[39m NetSimpleRejector(net_h_params, net_r_params)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 69\u001b[0m \u001b[43mrun_reject_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_2_r\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataLoaderTrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataLoaderTrainLabeled\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m model_dict \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(model_2_r\u001b[38;5;241m.\u001b[39mstate_dict())\n\u001b[1;32m     71\u001b[0m best_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/Documents/UT Austin/Research Projects/HAI_icebreaker/active_learn_to_defer/training_helpers.py:269\u001b[0m, in \u001b[0;36mrun_reject_class\u001b[0;34m(model, epochs, train_loader, val_loader, apply_softmax)\u001b[0m\n\u001b[1;32m    265\u001b[0m scheduler \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mlr_scheduler\u001b[39m.\u001b[39mCosineAnnealingLR(optimizer, \u001b[39mlen\u001b[39m(train_loader) \u001b[39m*\u001b[39m epochs)\n\u001b[1;32m    267\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, epochs):\n\u001b[1;32m    268\u001b[0m     \u001b[39m# train for one epoch\u001b[39;00m\n\u001b[0;32m--> 269\u001b[0m     train_reject_class(train_loader, model, optimizer, scheduler, epoch, apply_softmax)\n\u001b[1;32m    270\u001b[0m     \u001b[39m#if epoch % 10 == 0:\u001b[39;00m\n\u001b[1;32m    271\u001b[0m         \u001b[39m#metrics_print_classifier(model, val_loader)\u001b[39;00m\n\u001b[1;32m    273\u001b[0m \u001b[39mreturn\u001b[39;00m copy\u001b[39m.\u001b[39mdeepcopy(model\u001b[39m.\u001b[39mstate_dict())\n",
      "File \u001b[0;32m~/Documents/UT Austin/Research Projects/HAI_icebreaker/active_learn_to_defer/training_helpers.py:104\u001b[0m, in \u001b[0;36mtrain_reject_class\u001b[0;34m(train_loader, model, optimizer, scheduler, epoch, apply_softmax)\u001b[0m\n\u001b[1;32m    101\u001b[0m model\u001b[39m.\u001b[39mtrain()\n\u001b[1;32m    103\u001b[0m end \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m--> 104\u001b[0m \u001b[39mfor\u001b[39;00m i, (\u001b[39minput\u001b[39m, target, expert, _, _ ) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_loader):\n\u001b[1;32m    105\u001b[0m     target \u001b[39m=\u001b[39m target\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m    106\u001b[0m     \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/semi_active/lib/python3.10/site-packages/torch/utils/data/dataloader.py:681\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    678\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    679\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    680\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 681\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    682\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    683\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    684\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    685\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/semi_active/lib/python3.10/site-packages/torch/utils/data/dataloader.py:721\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    720\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 721\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    722\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    723\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/semi_active/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/semi_active/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn [7], line 20\u001b[0m, in \u001b[0;36mCifarExpertDataset.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124;03m\"\"\"Take the index of item and returns the image, label, expert prediction and index in original dataset\"\"\"\u001b[39;00m\n\u001b[1;32m     19\u001b[0m label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtargets[index]\n\u001b[0;32m---> 20\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43mtransform_test\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimages\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m expert_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexpert_preds[index]\n\u001b[1;32m     22\u001b[0m indice \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[index]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/semi_active/lib/python3.10/site-packages/torchvision/transforms/transforms.py:92\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     89\u001b[0m         _log_api_usage_once(\u001b[39mself\u001b[39m)\n\u001b[1;32m     90\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransforms \u001b[39m=\u001b[39m transforms\n\u001b[0;32m---> 92\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, img):\n\u001b[1;32m     93\u001b[0m     \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransforms:\n\u001b[1;32m     94\u001b[0m         img \u001b[39m=\u001b[39m t(img)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "'''\n",
    "we have a dataset that has all labels. \n",
    "A percentage of it also has expert labels.\n",
    "Joint: only train on labeled part\n",
    "Seperate: train classifier on all data, train rejector only on labeled part\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for trial in range(MAX_TRIALS):\n",
    "    joint = []\n",
    "    seperate = []\n",
    "    joint_semisupervised = []\n",
    "    for data_size in data_sizes:\n",
    "        print(f'\\n \\n datas size {data_size} \\n \\n')\n",
    "        print(f' \\n Joint \\n')\n",
    "\n",
    "        all_indices = list(range(len(train_dataset.indices)))\n",
    "        all_data_x = np.array(train_dataset.dataset.data)[train_dataset.indices]\n",
    "        all_data_y = np.array(train_dataset.dataset.targets)[train_dataset.indices]\n",
    "\n",
    "        intial_random_set = random.sample(all_indices, math.floor(data_size*len(all_indices)))\n",
    "        indices_labeled  = intial_random_set\n",
    "        indices_unlabeled= list(set(all_indices) - set(indices_labeled))\n",
    "\n",
    "        dataset_train_labeled = CifarExpertDataset(all_data_x[indices_labeled], all_data_y[indices_labeled], Expert.predict , [1]*len(indices_labeled), indices_labeled)\n",
    "        dataset_train_unlabeled = CifarExpertDataset(all_data_x[indices_unlabeled], all_data_y[indices_unlabeled], Expert.predict , [0]*len(indices_unlabeled), indices_unlabeled)\n",
    "\n",
    "        dataLoaderTrainLabeled = DataLoader(dataset=dataset_train_labeled, batch_size=128, shuffle=True,  num_workers=0, pin_memory=True)\n",
    "        dataLoaderTrainUnlabeled = DataLoader(dataset=dataset_train_unlabeled, batch_size=128, shuffle=True,  num_workers=0, pin_memory=True)\n",
    "\n",
    "        '''\n",
    "        net_h_params = [10] + [100,100,1000,500]\n",
    "        net_r_params = [1] + [100,100,1000,500]\n",
    "        model_2_r = NetSimpleRejector(net_h_params, net_r_params).to(device)\n",
    "        model_dict = run_reject(model_2_r, 10, Expert.predict, EPOCHS, 1, dataLoaderTrainLabeled, dataLoaderVal, True)\n",
    "        best_score = 0\n",
    "        best_model = None\n",
    "        best_alpha = 1\n",
    "        for alpha in alpha_grid:\n",
    "            print(f'alpha {alpha}')\n",
    "            model_2_r.load_state_dict(model_dict)\n",
    "            model_dict_alpha = run_reject(model_2_r, 10, Expert.predict, EPOCHS_ALPHA, alpha, dataLoaderTrainLabeled, dataLoaderTrainLabeled, True, 1)\n",
    "            model_2_r.load_state_dict(model_dict_alpha)\n",
    "            score = metrics_print(model_2_r, Expert.predict, n_dataset, dataLoaderTrainLabeled)['system accuracy']\n",
    "            if score >= best_score:\n",
    "                best_score =  score\n",
    "                best_model = model_dict_alpha\n",
    "                best_alpha = alpha\n",
    "\n",
    "\n",
    "\n",
    "        model_2_r.load_state_dict(best_model)\n",
    "        joint.append(metrics_print(model_2_r, Expert.predict, n_dataset, dataLoaderTest)['system accuracy'])\n",
    "        '''\n",
    "        print(f'\\n Joint semi-supervised')\n",
    "        net_h_params = [10] + [100,100,1000,500]\n",
    "        net_r_params = [1] + [100,100,1000,500]\n",
    "        model_2_r = NetSimpleRejector(net_h_params, net_r_params).to(device)\n",
    "        run_reject_class(model_2_r, EPOCHS, dataLoaderTrain, dataLoaderTrainLabeled)\n",
    "        model_dict = copy.deepcopy(model_2_r.state_dict())\n",
    "        best_score = 0\n",
    "        best_model = None\n",
    "        best_alpha = 1\n",
    "        for alpha in alpha_grid:\n",
    "            print(f'alpha {alpha}')\n",
    "            model_2_r.load_state_dict(model_dict)\n",
    "            model_dict_alpha = run_reject(model_2_r, 10, Expert.predict, EPOCHS_ALPHA, alpha, dataLoaderTrainLabeled, dataLoaderTrainLabeled, True, 1)\n",
    "            model_2_r.load_state_dict(model_dict_alpha)\n",
    "            score = metrics_print(model_2_r, Expert.predict, n_dataset, dataLoaderTrainLabeled)['system accuracy']\n",
    "            if score >= best_score:\n",
    "                best_score =  score\n",
    "                best_model = model_dict_alpha\n",
    "                best_alpha = alpha\n",
    "\n",
    "\n",
    "\n",
    "        model_2_r.load_state_dict(best_model)\n",
    "        joint_semisupervised.append(metrics_print(model_2_r, Expert.predict, n_dataset, dataLoaderTest)['system accuracy'])\n",
    "        '''\n",
    "        print(f' \\n Seperate \\n')\n",
    "        # seperate\n",
    "        model_expert = NetSimple(2,  100,100,1000,500).to(device)\n",
    "        run_expert(model_expert,EPOCHS, dataLoaderTrainLabeled, dataLoaderVal)\n",
    "\n",
    "        model_class = NetSimple(n_dataset, 100,100,1000,500).to(device)\n",
    "\n",
    "        run_reject_class(model_class, EPOCHS, dataLoaderTrain, dataLoaderVal)\n",
    "        seperate.append(metrics_print_2step(model_class, model_expert, Expert.predict, 10, dataLoaderTest)['system accuracy'])\n",
    "        '''\n",
    "    joint_results.append(joint)\n",
    "    seperate_results.append(seperate)\n",
    "    joint_semisupervised_results.append(joint_semisupervised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_h_params = [10] + [100,100,1000,500]\n",
    "net_r_params = [1] + [100,100,1000,500] \n",
    "model_2_r = NetSimpleRejector(net_h_params, net_r_params).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of model parameters: 6523911\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Mismatched Tensor types in NNPack convolutionOutput",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [36], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mrun_reject_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_2_r\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataLoaderTrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataLoaderTrainLabeled\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/UT Austin/Research Projects/HAI_icebreaker/active_learn_to_defer/training_helpers.py:269\u001b[0m, in \u001b[0;36mrun_reject_class\u001b[0;34m(model, epochs, train_loader, val_loader, apply_softmax)\u001b[0m\n\u001b[1;32m    265\u001b[0m scheduler \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mlr_scheduler\u001b[39m.\u001b[39mCosineAnnealingLR(optimizer, \u001b[39mlen\u001b[39m(train_loader) \u001b[39m*\u001b[39m epochs)\n\u001b[1;32m    267\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, epochs):\n\u001b[1;32m    268\u001b[0m     \u001b[39m# train for one epoch\u001b[39;00m\n\u001b[0;32m--> 269\u001b[0m     train_reject_class(train_loader, model, optimizer, scheduler, epoch, apply_softmax)\n\u001b[1;32m    270\u001b[0m     \u001b[39m#if epoch % 10 == 0:\u001b[39;00m\n\u001b[1;32m    271\u001b[0m         \u001b[39m#metrics_print_classifier(model, val_loader)\u001b[39;00m\n\u001b[1;32m    273\u001b[0m \u001b[39mreturn\u001b[39;00m copy\u001b[39m.\u001b[39mdeepcopy(model\u001b[39m.\u001b[39mstate_dict())\n",
      "File \u001b[0;32m~/Documents/UT Austin/Research Projects/HAI_icebreaker/active_learn_to_defer/training_helpers.py:108\u001b[0m, in \u001b[0;36mtrain_reject_class\u001b[0;34m(train_loader, model, optimizer, scheduler, epoch, apply_softmax)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m    107\u001b[0m \u001b[39m# compute output\u001b[39;00m\n\u001b[0;32m--> 108\u001b[0m output \u001b[39m=\u001b[39m model(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    110\u001b[0m \u001b[39m# compute loss\u001b[39;00m\n\u001b[1;32m    111\u001b[0m \u001b[39mif\u001b[39;00m apply_softmax:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/semi_active/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/UT Austin/Research Projects/HAI_icebreaker/active_learn_to_defer/neural_network.py:198\u001b[0m, in \u001b[0;36mNetSimpleRejector.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m--> 198\u001b[0m     x_h \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnet_h(x)\n\u001b[1;32m    199\u001b[0m     x_r \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnet_r(x)\n\u001b[1;32m    200\u001b[0m     x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat((x_h, x_r), \u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/semi_active/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/UT Austin/Research Projects/HAI_icebreaker/active_learn_to_defer/neural_network.py:178\u001b[0m, in \u001b[0;36mNetSimpleRaw.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m--> 178\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpool(F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv1(x)))\n\u001b[1;32m    179\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpool(F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv2(x)))\n\u001b[1;32m    180\u001b[0m     x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mflatten(x, \u001b[39m1\u001b[39m) \u001b[39m# flatten all dimensions except batch\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/semi_active/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/semi_active/lib/python3.10/site-packages/torch/nn/modules/conv.py:457\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 457\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/semi_active/lib/python3.10/site-packages/torch/nn/modules/conv.py:453\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    450\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    451\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    452\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> 453\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    454\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Mismatched Tensor types in NNPack convolutionOutput"
     ]
    }
   ],
   "source": [
    "run_reject_class(model_2_r, EPOCHS, dataLoaderTrain, dataLoaderTrainLabeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_reject(model_2_r, 10, Expert.predict, EPOCHS_ALPHA, alpha, dataLoaderTrainLabeled, dataLoaderTrainLabeled, True, 1)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = metrics_print(model_2_r, Expert.predict, n_dataset, dataLoaderTrainLabeled)['system accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "id": "pgkPyQ3_Iu_i",
    "outputId": "5de32290-c568-4d10-9e13-a4ddb1ffadbd"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "avgs_rand = [np.average([joint_results[triall][i]  for triall in range(MAX_TRIALS)]) for i in range(len(data_sizes))]\n",
    "stds_rand = [np.std([joint_results[triall][i] for triall in range(MAX_TRIALS)]) for i in range(len(data_sizes))]\n",
    "plt.errorbar(data_sizes ,  avgs_rand, yerr=stds_rand, marker = \"x\",  label=f'Joint')\n",
    "\n",
    "\n",
    "\n",
    "avgs_rand = [np.average([ seperate_results[triall][i]  for triall in range(MAX_TRIALS)]) for i in range(len(data_sizes))]\n",
    "stds_rand = [np.std([seperate_results[triall][i] for triall in range(MAX_TRIALS)]) for i in range(len(data_sizes))]\n",
    "plt.errorbar(data_sizes ,  avgs_rand, yerr=stds_rand, marker = \"o\",  label=f'Staged')\n",
    "\n",
    "\n",
    "avgs_rand = [np.average([ joint_semisupervised_results[triall][i]  for triall in range(MAX_TRIALS)]) for i in range(len(data_sizes))]\n",
    "stds_rand = [np.std([joint_semisupervised_results[triall][i] for triall in range(MAX_TRIALS)]) for i in range(len(data_sizes))]\n",
    "plt.errorbar(data_sizes ,  avgs_rand, yerr=stds_rand, marker = \"*\",  label=f'Joint-SemiSupervised')\n",
    "\n",
    "\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.get_xaxis().tick_bottom()    \n",
    "ax.get_yaxis().tick_left()   \n",
    "plt.grid()\n",
    "plt.legend(fontsize='large')\n",
    "plt.legend(loc =\"lower right\")\n",
    "plt.ylabel('System Accuracy',  fontsize='x-large')\n",
    "plt.xlabel('Fraction of data Labeled', fontsize='x-large')\n",
    "fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "fig_size[0] = 6\n",
    "fig_size[1] = 4\n",
    "plt.savefig(\"sample_complexity_cifar.pdf\", dpi = 1000)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "WvmtEh42mViU"
   ],
   "name": "joint_v_seperate_sample_complex.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit ('semi_active')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "6b80e4cca43c3aa8f2cc694515055a8f5e01fb8f0dcaf7c6584df02e1fc8b170"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "08a984939466469787ceeaed669b837a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b9a72ba4fd4c4e51b2e18240c4144066",
      "placeholder": "​",
      "style": "IPY_MODEL_b5a8afad6ae54f63ad4a491e1b1f7878",
      "value": " 170499072/? [00:04&lt;00:00, 52586018.71it/s]"
     }
    },
    "13afdf908e9d429ebf46f0805ccc84c8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2d83b4dbdb93474b94d67299c9d0c403": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6e49c91cb70049e68eeb1396ead9d39e",
      "placeholder": "​",
      "style": "IPY_MODEL_13afdf908e9d429ebf46f0805ccc84c8",
      "value": ""
     }
    },
    "343a6794baea4d56b8d943ffc5c8a3e5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "388a5b0fe7b84ba88a618affdc70d5b4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2d83b4dbdb93474b94d67299c9d0c403",
       "IPY_MODEL_8676435c0184460ebf790190a7acce63",
       "IPY_MODEL_08a984939466469787ceeaed669b837a"
      ],
      "layout": "IPY_MODEL_343a6794baea4d56b8d943ffc5c8a3e5"
     }
    },
    "6e49c91cb70049e68eeb1396ead9d39e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6efc410ba6a74ba0a1c1b29fc2d32957": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8676435c0184460ebf790190a7acce63": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6efc410ba6a74ba0a1c1b29fc2d32957",
      "max": 170498071,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_92dbd1bb64514b3c8b510408a5fd59db",
      "value": 170498071
     }
    },
    "92dbd1bb64514b3c8b510408a5fd59db": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b5a8afad6ae54f63ad4a491e1b1f7878": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b9a72ba4fd4c4e51b2e18240c4144066": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
